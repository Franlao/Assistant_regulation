# LangGraph Implementation for Assistant Regulation

## üéØ Vue d'Ensemble

Cette impl√©mentation LangGraph remplace progressivement l'architecture orchestrateur existante avec une approche multi-agent moderne, tout en **r√©utilisant 100% de vos services m√©tier existants**.

## üìÅ Structure

```
assistant_regulation/planning/langgraph/
‚îú‚îÄ‚îÄ __init__.py                     # Exports principaux
‚îú‚îÄ‚îÄ orchestrator.py                 # üéØ Orchestrateur principal LangGraph
‚îú‚îÄ‚îÄ compatibility_adapter.py        # Adaptateur de compatibilit√©
‚îú‚îÄ‚îÄ README.md                      # Cette documentation
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ state/                         # √âtats partag√©s
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ regulation_state.py        # TypedDict pour l'√©tat workflow
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ agents/                        # Agents LangGraph
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ supervisor_agent.py        # üëë Agent superviseur
‚îÇ   ‚îú‚îÄ‚îÄ routing_agent.py           # üß≠ Agent de routage
‚îÇ   ‚îú‚îÄ‚îÄ retrieval_agent.py         # üîç Agent de r√©cup√©ration
‚îÇ   ‚îú‚îÄ‚îÄ validation_agent.py        # ‚úÖ Agent de validation
‚îÇ   ‚îî‚îÄ‚îÄ generation_agent.py        # ‚ú® Agent de g√©n√©ration
‚îî‚îÄ‚îÄ 
‚îî‚îÄ‚îÄ workflows/                     # D√©finitions des graphes
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ regulation_workflow.py     # Workflow principal
    ‚îî‚îÄ‚îÄ streaming_workflow.py      # Workflow streaming
```

## üöÄ Utilisation Rapide

### Remplacement Direct du ModularOrchestrator

```python
# Avant (ModularOrchestrator)
from assistant_regulation.planning.sync.modular_orchestrator import ModularOrchestrator

orchestrator = ModularOrchestrator(
    llm_provider="ollama",
    model_name="llama3.2",
    enable_verification=True
)

# Apr√®s (LangGraphOrchestrator)
from assistant_regulation.planning.langgraph import LangGraphOrchestrator

orchestrator = LangGraphOrchestrator(
    llm_provider="ollama",
    model_name="llama3.2",
    enable_verification=True,
    workflow_type="full"  # üÜï Nouveau param√®tre
)

# Interface identique !
result = orchestrator.process_query("Votre question r√©glementaire")
```

### Migration Progressive avec Adaptateur

```python
from assistant_regulation.planning.langgraph.compatibility_adapter import LangGraphCompatibilityAdapter

# Adaptateur avec fallback automatique
orchestrator = LangGraphCompatibilityAdapter(
    llm_provider="ollama",
    model_name="llama3.2",
    enable_verification=True,
    workflow_type="full",
    fallback_to_modular=True  # Utilise ModularOrchestrator si LangGraph √©choue
)

# Interface 100% compatible
result = orchestrator.process_query("Votre question")
```

## üèóÔ∏è Types de Workflows

### 1. Workflow Full (Recommand√©)
```python
orchestrator = LangGraphOrchestrator(workflow_type="full")
```
- **Agents**: Supervisor ‚Üí Routing ‚Üí Retrieval ‚Üí Validation ‚Üí Generation
- **Usage**: Questions complexes n√©cessitant RAG complet
- **Performances**: Optimal pour qualit√©

### 2. Workflow Simple
```python
orchestrator = LangGraphOrchestrator(workflow_type="simple")
```
- **Agents**: Supervisor ‚Üí Generation
- **Usage**: Questions simples sans RAG
- **Performances**: Tr√®s rapide

### 3. Workflow Streaming
```python
orchestrator = LangGraphOrchestrator(workflow_type="streaming")
```
- **Agents**: Optimis√©s pour r√©ponse temps r√©el
- **Usage**: Interface utilisateur interactive
- **Performances**: Latence minimale

### 4. Workflow Debug
```python
orchestrator = LangGraphOrchestrator(workflow_type="debug", enable_debug=True)
```
- **Agents**: Tous avec traces d√©taill√©es
- **Usage**: D√©veloppement et debugging
- **Performances**: Verbose mais informatif

## üîÑ Agents et Services

### Mapping Services ‚Üí Agents

| Service Existant | Agent LangGraph | R√¥le |
|------------------|----------------|------|
| `MasterRoutingService` | `SupervisorAgent` | Coordination g√©n√©rale |
| `IntelligentRoutingService` | `RoutingAgent` | Routage intelligent |
| `RetrievalService` | `RetrievalAgent` | Recherche multimodale |
| `ValidationService` | `ValidationAgent` | Validation chunks |
| `GenerationService` | `GenerationAgent` | G√©n√©ration r√©ponse |
| `MemoryService` | `GenerationAgent` | M√©moire conversationnelle |

### Architecture du Workflow

```mermaid
graph TD
    A[üë§ User Query] --> B[üëë SupervisorAgent]
    B --> C{Needs RAG?}
    C -->|Yes| D[üß≠ RoutingAgent]
    C -->|No| H[‚ú® GenerationAgent]
    D --> E[üîç RetrievalAgent]
    E --> F[‚úÖ ValidationAgent]
    F --> G[üìù ContextBuilder]
    G --> H
    H --> I[üìã Final Response]
```

## üí° Fonctionnalit√©s Avanc√©es

### 1. Streaming Temps R√©el

```python
# Streaming avec LangGraph
for event in orchestrator.process_query_stream("Votre question"):
    print(f"[{event['type']}] {event.get('message', '')}")
```

### 2. Changement Dynamique de Workflow

```python
# Changer de workflow √† la vol√©e
orchestrator.switch_workflow("streaming")  # Pour interface temps r√©el
orchestrator.switch_workflow("simple")     # Pour questions rapides
orchestrator.switch_workflow("debug")      # Pour debugging
```

### 3. Statistiques et Observabilit√©

```python
# Statistiques d√©taill√©es
stats = orchestrator.get_agent_statistics()
print(f"Workflow actif: {stats['workflow_type']}")
print(f"Agents initialis√©s: {stats['agents_initialized']}")
print(f"Temps moyen: {stats['processing_stats']['total_processing_time']}")
```

### 4. Comparaison Performance

```python
# Comparer LangGraph vs ModularOrchestrator
adapter = LangGraphCompatibilityAdapter(fallback_to_modular=True)
comparison = adapter.run_comparison_test("Votre question test")
print(comparison)
```

## üìä Avantages vs Architecture Actuelle

| Aspect | ModularOrchestrator | LangGraphOrchestrator |
|--------|-------------------|---------------------|
| **Complexit√© Code** | 230+ lignes | 150 lignes core |
| **Orchestration** | Manuelle | Graphique native |
| **Observabilit√©** | Logs basiques | Traces compl√®tes |
| **Extensibilit√©** | Difficile | Tr√®s facile |
| **Debugging** | Complex | Visuel + traces |
| **Streaming** | Basique | Optimis√© |
| **Parall√©lisation** | Limit√©e | Native |
| **Maintenance** | √âlev√©e | Faible |

## üõ†Ô∏è Installation et Pr√©requis

### D√©pendances Suppl√©mentaires

```bash
pip install langgraph langchain langchain-openai
```

### Configuration Minimale

```python
# Vos services existants continuent de fonctionner !
# Aucune modification requise dans :
# - RetrievalService
# - GenerationService  
# - ValidationService
# - MemoryService
# - Tous les services de routage
```

## üîß Migration √âtape par √âtape

### √âtape 1: Installation
```bash
pip install langgraph langchain
```

### √âtape 2: Test avec Adaptateur
```python
from assistant_regulation.planning.langgraph.compatibility_adapter import LangGraphCompatibilityAdapter

# Test avec fallback automatique
orchestrator = LangGraphCompatibilityAdapter(fallback_to_modular=True)
result = orchestrator.process_query("Test")
```

### √âtape 3: Migration Progressive
```python
# Remplacer progressivement les imports
# from assistant_regulation.planning.sync.modular_orchestrator import ModularOrchestrator
from assistant_regulation.planning.langgraph import LangGraphOrchestrator as ModularOrchestrator

# Code client inchang√© !
```

### √âtape 4: Optimisation
```python
# Utiliser les nouvelles fonctionnalit√©s
orchestrator.switch_workflow("streaming")
stats = orchestrator.get_agent_statistics()
```

## üêõ Debugging et D√©veloppement

### Mode Debug Complet

```python
orchestrator = LangGraphOrchestrator(
    workflow_type="debug",
    enable_debug=True
)

result = orchestrator.process_query("Test debug")
# Affiche automatiquement:
# === SUPERVISOR START ===
# Current state keys: ['query', 'conversation_context', ...]
# === SUPERVISOR END ===
# === ROUTING START ===
# ...
```

### Traces d'Ex√©cution

```python
result = orchestrator.process_query("Test")
trace = result['metadata']['agent_trace']
print(f"Agents ex√©cut√©s: {trace}")
# ['supervisor_start', 'supervisor_complete', 'routing_start', ...]
```

## üìà Performances et Monitoring

### M√©triques Automatiques

```python
stats = orchestrator.get_conversation_stats()
print(f"Requ√™tes trait√©es: {stats['queries_processed']}")
print(f"Temps moyen: {stats['total_processing_time'] / stats['queries_processed']:.2f}s")
print(f"Taux d'erreur: {stats['errors'] / stats['queries_processed']:.2%}")
```

### Int√©gration LangSmith (Optionnel)

```python
# Configuration pour observabilit√© avanc√©e
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your-key"

# Traces automatiques dans LangSmith !
```

## üéØ Exemple Complet

```python
from assistant_regulation.planning.langgraph import LangGraphOrchestrator

# Initialisation
orchestrator = LangGraphOrchestrator(
    llm_provider="ollama",
    model_name="llama3.2",
    enable_verification=True,
    workflow_type="full"
)

# Utilisation classique
result = orchestrator.process_query(
    "Quels sont les crit√®res de s√©curit√© pour les syst√®mes de freinage ?",
    use_images=True,
    use_tables=True,
    top_k=5
)

print(f"R√©ponse: {result['answer']}")
print(f"Sources: {len(result['sources'])}")
print(f"Temps: {result['metadata']['processing_time']:.2f}s")

# Streaming
for event in orchestrator.process_query_stream("Question streaming"):
    if event['type'] == 'generation_chunk':
        print(event['content'], end='', flush=True)

# Statistiques
stats = orchestrator.get_agent_statistics()
print(f"Workflow: {stats['workflow_type']}")
```

## ü§ù Compatibilit√©

- ‚úÖ **100% compatible** avec interface ModularOrchestrator
- ‚úÖ **0% de refactoring** requis dans vos services
- ‚úÖ **Migration progressive** sans interruption
- ‚úÖ **Fallback automatique** en cas de probl√®me
- ‚úÖ **M√™me format** de r√©ponses et m√©tadonn√©es

---

## üéâ Pr√™t √† Migrer ?

1. **Testez** avec `LangGraphCompatibilityAdapter`
2. **Comparez** les performances avec `run_comparison_test()`
3. **Migrez** progressivement avec `switch_workflow()`
4. **Optimisez** avec les nouvelles fonctionnalit√©s LangGraph

**Votre code m√©tier reste inchang√© - seule l'orchestration devient plus puissante !** üöÄ